# Oslo
oslo.lat <- 59.911491
oslo.long <- 10.757933
View(stations.data)
stations.data.pos <- unlist(stations.data$geometry.coordinates)
stations.data$longitude <- stations.data.pos[seq(1, length(stations.data.pos), 2)]
stations.data
stations.data$geometry.coordinates
unlist(stations.data$geometry.coordinates)
stations.data$latitude <-  stations.data.pos[seq(2, length(stations.data.pos), 2)]
stations.data <- stations.data[!is.na(stations.data$geometry.coordinates),]
stations.data.pos <- unlist(stations.data$geometry.coordinates)
stations.data$longitude <- stations.data.pos[seq(1, length(stations.data.pos), 2)]
stations.data <- stations.data[stations.data$geometry.coordinates == "NULL",]
endpoint <- paste0("https://", client_id, "@frost.met.no/sources/v0.jsonld", collapse=NULL)
url <- endpoint
xs <- try(fromJSON(URLencode(url),flatten=T))
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
stations.data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
library(geosphere) # to calculate distance latitude and longitude
# Oslo
oslo.lat <- 59.911491
oslo.long <- 10.757933
stations.data <- stations.data[!is.na(stations.data$geometry.coordinates),]
stations.data <- stations.data[stations.data$geometry.coordinates != "NULL",]
stations.data.pos <- unlist(stations.data$geometry.coordinates)
stations.data$longitude <- stations.data.pos[seq(1, length(stations.data.pos), 2)]
stations.data$latitude <-  stations.data.pos[seq(2, length(stations.data.pos), 2)]
stations.data$distOslo <- distm(stations.data[,c("latitude", "longitude")], c(oslo.lat, oslo.long))
maxDistOslo <- 15000
stations.data <- stations.data[stations.data$distOslo <= maxDistOslo,]
write.csv(stations.data,file = "weatherstationsOslo15000")
write.csv(stations.data,file = "weatherstationsOslo15000.csv")
paste(stations.data$id, collapse = ",")
# Define andpoint and parameters
endpoint <- paste0("https://", client_id, "@frost.met.no/observations/v0.jsonld", collapse=NULL)
sources <- paste(stations.data$id, collapse = ",")
elements <- 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)'
referenceTime <- '2000-04-01/2019-04-03'
# Build the URL to Frost
url <- paste0(
endpoint, "?",
"sources=", sources,
"&referencetime=", referenceTime,
"&elements=", elements,
collapse=NULL
)
# Issue an HTTP GET request and extract JSON data
xs <- try(fromJSON(URLencode(url),flatten=T))
# Define andpoint and parameters
endpoint <- paste0("https://", client_id, "@frost.met.no/observations/v0.jsonld", collapse=NULL)
sources <- paste(stations.data$id, collapse = ",")
elements <- 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)'
referenceTime <- '2000-04-01/2019-04-03'
# Build the URL to Frost
url <- paste0(
endpoint, "?",
"sources=", sources,
"&referencetime=", referenceTime,
"&elements=", elements,
collapse=NULL
)
# Issue an HTTP GET request and extract JSON data
xs <- try(fromJSON(URLencode(url),flatten=T))
# Define andpoint and parameters
endpoint <- paste0("https://", client_id, "@frost.met.no/observations/v0.jsonld", collapse=NULL)
sources <- paste(stations.data$id, collapse = ",")
elements <- 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)'
referenceTime <- '2018-04-01/2019-04-03'
# Build the URL to Frost
url <- paste0(
endpoint, "?",
"sources=", sources,
"&referencetime=", referenceTime,
"&elements=", elements,
collapse=NULL
)
# Issue an HTTP GET request and extract JSON data
xs <- try(fromJSON(URLencode(url),flatten=T))
# Check if the request worked, print out any errors
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
# Check if the request worked, print out any errors
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
```{r}
# This will return a Dataframe with all of the observations in a table format
df <- data.frame()
# Check if the request worked, print out any errors
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
View(data)
View(data[[3]][[1]])
View(data[[3]][[22]])
View(data[[3]][[143]])
View(data[[3]][[336]])
# This will return a Dataframe with all of the observations in a table format
df <- data.frame()
for (i in 1:length(data$observations)) {
row <- data$observations[[i]]
row$sourceId <- data$sourceId[[i]]
row$referenceTime <- data$referenceTime[[i]]
df <- rbind(df, row)
}
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(jsonlite)
client_id  = 'eb040e3c-5830-4086-af49-a06b3e1e2daf'
# Chunk 3
endpoint <- paste0("https://", client_id, "@frost.met.no/locations/v0.jsonld", collapse=NULL)
url <- endpoint
xs <- try(fromJSON(URLencode(url),flatten=T))
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
stations.data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
library(geosphere) # to calculate distance latitude and longitude
# Oslo
oslo.lat <- 59.911491
oslo.long <- 10.757933
typeof(stations.data$geometry.coordinates[1])
stations.data$point <- unlist(stations.data$geometry.coordinates)
stations.data.pos <- unlist(stations.data$geometry.coordinates)
stations.data$longitude <- stations.data.pos[seq(1, length(stations.data.pos), 2)]
stations.data$latitude <-  stations.data.pos[seq(2, length(stations.data.pos), 2)]
stations.data$distOslo <- distm(stations.data[,c("latitude", "longitude")], c(oslo.lat, oslo.long))
maxDistOslo <- 15000
stations.data <- stations.data[stations.data$distOslo <= maxDistOslo,]
write.csv(stations.data,file = "weatherstationsOslo15000")
# Chunk 4
endpoint <- paste0("https://", client_id, "@frost.met.no/sources/v0.jsonld", collapse=NULL)
url <- endpoint
xs <- try(fromJSON(URLencode(url),flatten=T))
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
stations.data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
library(geosphere) # to calculate distance latitude and longitude
# Oslo
oslo.lat <- 59.911491
oslo.long <- 10.757933
stations.data <- stations.data[!is.na(stations.data$geometry.coordinates),]
stations.data <- stations.data[stations.data$geometry.coordinates != "NULL",]
stations.data.pos <- unlist(stations.data$geometry.coordinates)
stations.data$longitude <- stations.data.pos[seq(1, length(stations.data.pos), 2)]
stations.data$latitude <-  stations.data.pos[seq(2, length(stations.data.pos), 2)]
stations.data$distOslo <- distm(stations.data[,c("latitude", "longitude")], c(oslo.lat, oslo.long))
maxDistOslo <- 15000
stations.data <- stations.data[stations.data$distOslo <= maxDistOslo,]
# Chunk 5
# Define andpoint and parameters
endpoint <- paste0("https://", client_id, "@frost.met.no/observations/v0.jsonld", collapse=NULL)
sources <- paste(stations.data$id, collapse = ",")
elements <- 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)'
referenceTime <- '2018-04-01/2019-04-03'
# Build the URL to Frost
url <- paste0(
endpoint, "?",
"sources=", sources,
"&referencetime=", referenceTime,
"&elements=", elements,
collapse=NULL
)
# Issue an HTTP GET request and extract JSON data
xs <- try(fromJSON(URLencode(url),flatten=T))
# Chunk 6
# Check if the request worked, print out any errors
if (class(xs) != 'try-error') {
print("Data retrieved from frost.met.no!")
data <- xs$data
} else {
print("Error: the data retrieval was not successful!")
}
# This will return a Dataframe with all of the observations in a table format
df <- data.frame()
for (i in 1:length(data$observations)) {
row <- data$observations[[i]]
row$sourceId <- data$sourceId[[i]]
row$referenceTime <- data$referenceTime[[i]]
df <- rbind(df, row)
}
View(df)
View(df)
View(row)
View(row)
View(df)
data$observations[10]
data$observations[14]
data$observations[16]
knitr::opts_chunk$set(echo = TRUE)
df <- read.csv("scooter_parsed.csv")
df <- read.csv("scooter_parsed.csv")
names(df) <- c("id", "company", "Latitude", "Longitude", "shortID","perc","time")
names(df) <- c("index","id", "company", "Latitude", "Longitude", "shortID","perc","time")
df <- df %>%
group_by(id) %>%
mutate(standstill = ifelse((Latitude == lag(Latitude)) & (Longitude == lag(Longitude)), lag(standstill)+1, 0))
library(dplyr)
df <- df %>%
group_by(id) %>%
mutate(standstill = ifelse((Latitude == lag(Latitude)) & (Longitude == lag(Longitude)), lag(standstill)+1, 0))
df <- df %>%
group_by(id) %>%
mutate(standstill = ifelse((Latitude == lag(Latitude)) & (Longitude == lag(Longitude)), 1, 0))
View(df)
df <- df[df$standstill == 0,]
df <- read.csv("scooter_parsed.csv")
df <- read.csv("scooter_parsed.csv")
names(df) <- c("index","id", "company", "Latitude", "Longitude", "shortID","perc","time")
df$standstill = 0
library(dplyr)
df <- df %>%
group_by(id) %>%
mutate(standstill = ifelse((Latitude == lag(Latitude)) & (Longitude == lag(Longitude)), 1, 0))
View(df)
df <- df[df$standstill != 1 ,]
df <- df[,-"standstill"]
df <- df[,-c("standstill")]
df <- df[, c("index","id", "company", "Latitude", "Longitude", "shortID","perc","time")]
df <- read.csv("scooter_parsed.csv")
df <- read.csv("scooter_parsed.csv")
names(df) <- c("index","id", "company", "Latitude", "Longitude", "shortID","perc","time")
library(dplyr)
df <- df %>%
group_by(id) %>%
mutate(standstill = ifelse((Latitude == lag(Latitude)) & (Longitude == lag(Longitude)), 1, 0))
df <- df[df$standstill != 1 ,]
df <- df[,-c("standstill")]
df
knitr::opts_chunk$set(echo = TRUE)
df <- read.csv("processed-data/output1.csv")
df <- df[!is.na(df$time),]
df <- read.csv("processed-data/output1.csv")
nrow(df[!is.na(df$time),])
nrow(df[is.na(df$time),])
df[8362811-10,]
df[8362811-10,"time"]
df[8362811-10,]$time
df$time <- as.POSIXct(df$time, format="%Y-%m-%d %H:%M:%S")
nrow(df[is.na(df$time),])
df <- df[!is.na(df$time),]
df3 <- read.csv("processed-data/scooter_parsed.csv")
df3$time <- as.POSIXct(df3$time, format="%d/%m/%Y %H:%M:%S")
df3 <- read.csv("processed-data/scooter_parsed.csv")
df3$time <- as.POSIXct(df3$time, format="%d/%m/%Y %H:%M")
df4 <- rbind(df, df3)
df4 <- rbind(df, df3, fill = T)
library(dplyr)
df4 <- rbind.fill(df, df3)
library(plyr)
df4 <- rbind.fill(df, df3)
write.csv(df4, "output1.csv")
df <- read.csv("processed-data/output1.csv")
df$day <- df$time$day
df$day <- df$time
df$time <- as.POSIXct(df$time, format="%d/%m/%Y %H:%M")
df$time <- df$day
df$time <- as.POSIXct(df$time, format="%Y-%-%Y %H:%M")
df[is.na(df$time),]
knitr::opts_chunk$set(echo = TRUE)
df2 <- read.csv("processed-data/output1.csv")
df <- read.csv("processed-data/output1.csv")
df$time <- as.POSIXct(df$time, format="%Y-%m-%d %H:%M:%S")
df <- df %>% group_by(operator, id) %>% mutate(isEnd = ifelse((lead(distanceTravelled)<50 | lead(distanceTravelled)>15000) & (distanceTravelled > 50 | distanceTravelled > 15000),1,0),
isStart = ifelse((distanceTravelled < 50 | distanceTravelled > 15000) & (lead(distanceTravelled) > 50 & lead(distanceTravelled) < 15000),1,0),
isMidTour = ifelse(lag(distanceTravelled) > 50 & lag(distanceTravelled) < 15000 & lead(distanceTravelled) > 50 & lead(distanceTravelled) < 15000,1,0)) %>% ungroup()
library(dplyr)
df <- df %>% group_by(operator, id) %>% mutate(isEnd = ifelse((lead(distanceTravelled)<50 | lead(distanceTravelled)>15000) & (distanceTravelled > 50 | distanceTravelled > 15000),1,0),
isStart = ifelse((distanceTravelled < 50 | distanceTravelled > 15000) & (lead(distanceTravelled) > 50 & lead(distanceTravelled) < 15000),1,0),
isMidTour = ifelse(lag(distanceTravelled) > 50 & lag(distanceTravelled) < 15000 & lead(distanceTravelled) > 50 & lead(distanceTravelled) < 15000,1,0)) %>% ungroup()
df.t <- df[df$id =="2d656da8-5a5c-4d6d-a824-f6f7fd4389ff",]
View(df.t)
View(df)
df <- df %>% group_by(operator, id) %>% mutate(isEnd = ifelse((lead(distanceTravelled)<50 | lead(distanceTravelled)>15000) & (distanceTravelled > 50 | distanceTravelled > 15000),1,0),
isStart = ifelse((distanceTravelled < 50 | distanceTravelled > 15000) & (lead(distanceTravelled) > 50 & lead(distanceTravelled) < 15000),1,0),
isMidTour = ifelse(lag(distanceTravelled) > 50 & lag(distanceTravelled) < 15000 & lead(distanceTravelled) > 50 & lead(distanceTravelled) < 15000,1,0)) %>% ungroup()
df.t <- df[df$id =="6223e93e-43f0-4c82-b082-d90f81c3cb9a	",]
df.t <- df[df$id =="6223e93e-43f0-4c82-b082-d90f81c3cb9a",]
df$day <- format(df$time,"%d")
df$month <- format(df$time,"%m")
df$year <- format(df$time,"%Y")
df.t <- df[df$id =="6223e93e-43f0-4c82-b082-d90f81c3cb9a",]
View(df.t)
df <- df[!is.na(df$Unnamed..0)]
df <- df[!is.na(df$Unnamed..0),]
View(df)
df.t <- df[df$isStart ==1,]
View(df.t)
df <- na.omit(df)
df.t <- df[df$isStart ==1,]
View(df.t)
setwd("~/scooteranalysis")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plotly)
library(dplyr)
# Chunk 3
# Reading data
df <- read.csv("processed-data/output10min.csv")
df <- df[,-c(1,2)]
df$time <- as.POSIXct(df$time, "%Y-%m-%d %H:%M:%S", tz="Europe/Paris")
df$day <- strftime(df$time, format = "%d")
df$month <- strftime(df$time, format = "%m")
df$year <- strftime(df$time, format = "%Y")
df$hour <- strftime(df$time, format = "%H")
# Chunk 4
summary(df)
# Chunk 5
# Number of unique scooters per day
df.unique <- df %>% group_by(operator,time) %>% summarise(n = n_distinct(id))
p <- ggplot(df.unique, aes(x=time, y = n, color = operator)) +
geom_line() +
ggtitle("Unique scooter ids in Oslo") +
ylab("Number of unique scooter ids") +
xlab("Time") +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
# Chunk 6
df.trips <- df[df$distanceTravelled > 50 & df$distanceTravelled < 15000,]
p <- ggplot(df.trips, aes(x = distanceTravelled, fill = operator)) +
geom_histogram(colour='black',size=0.1, breaks = seq(0,15000,500)) +
xlab("Distance travelled") +
ylab("Count") +
ggtitle("Scooter movements count on distance") +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
p <- ggplot(df.trips, aes(x = distanceTravelled, fill = operator)) +
geom_histogram(colour='black',size=0.1, breaks = seq(0,15000,500), position="fill") +
xlab("Distance travelled") +
ylab("Count") +
ggtitle("Scooter movements density on distance") +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
# Chunk 7
# Finding start and end of trips
df.trip <- df %>% group_by(operator, id) %>% mutate(isEnd = ifelse((lead(distanceTravelled)<50 | lead(distanceTravelled)>3000) & (distanceTravelled > 50 | distanceTravelled > 3000),1,0),
isStart = ifelse((distanceTravelled < 50 | distanceTravelled > 3000) & (lead(distanceTravelled) > 50 & lead(distanceTravelled) < 3000),1,0)) %>% ungroup()
# Finding intervals part of a trip inbetween strat and end.
df.trip <- df.trip %>% group_by(operator, id) %>% mutate(isMid = ifelse((lead(isStart) == 1 | (lead(distanceTravelled)> 50 & lead(distanceTravelled) < 3000)) & (lag(distanceTravelled)> 50 & lag(distanceTravelled) < 3000),1,0)) %>% ungroup()
# Chunk 8
df.trip$monthDay <- strftime(df$time, format = "%m/%d")
df.start <- df.trip[df.trip$isStart == 1,]
df.start <- df.start[!is.na(df.start$time),]
p <- ggplot(df.start, aes(x = monthDay, fill = operator, colour='black',size=0.02)) + geom_bar(aes(y=..count..), position='dodge',colour='black',size=0.02) +
xlab("Day") +
ylab("Count") +
ggtitle("Estimated scooter trips per day") +
theme(axis.text.x = element_text(angle = 90)) +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
# Chunk 9
df.start.perScooter <- df.trip[!is.na(df.trip$isStart),]
df.start.perScooter <- df.start.perScooter %>%
group_by(operator, monthDay) %>%
summarise(averageTripsPerScooter = sum(isStart) / length(unique(id))) %>%
ungroup()
p <- ggplot(df.start.perScooter, aes(x = monthDay, y = averageTripsPerScooter, fill=operator), colour='black',size=0.02) +
geom_bar(stat="identity", position=position_dodge(), colour='black',size=0.02) +
xlab("Day") +
ylab("Average trips per scooter") +
ggtitle("Estimated average trips per scooter") +
theme(axis.text.x = element_text(angle = 90)) +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
# Chunk 10
df.start.perScooter <- df.trip[!is.na(df.trip$isStart),]
df.start.perScooter <- df.start.perScooter %>%
group_by(operator, hour) %>%
summarise(averageTripsPerScooter = sum(isStart) / length(unique(id)) / length(unique(cbind(month, day)))) %>%
ungroup()
p <- ggplot(df.start.perScooter, aes(x = hour, y = averageTripsPerScooter, fill=operator), colour='black',size=0.02) +
geom_bar(stat="identity", colour='black',size=0.02) +
xlab("Hour of day") +
ylab("Average trips per scooter") +
ggtitle("Estimated average trips per scooter (adjusted for days logged)") +
theme(axis.text.x = element_text(angle = 90)) +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
# Chunk 11
df.start.perScooter <- df.trip[!is.na(df.trip$isStart),]
df.start.perScooter$day <- weekdays(df.start.perScooter$time, abbreviate = T)
df.start.perScooter <- df.start.perScooter %>%
group_by(operator, day) %>%
summarise(averageTripsPerScooter = sum(isStart) / length(unique(id)) / length(unique(cbind(month, day)))) %>%
ungroup()
p <- ggplot(df.start.perScooter, aes(x = day, y = averageTripsPerScooter, fill=operator), colour='black',size=0.02) +
geom_bar(stat="identity", colour='black',size=0.02,position='dodge') +
xlab("Day of week") +
ylab("Average trips per scooter") +
ggtitle("Estimated average trips per scooter (adjusted for days logged)") +
theme(axis.text.x = element_text(angle = 90)) +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
df.power <- df %>%
group_by(operator, hour) %>%
summarise(power = mean(power)) %>%
ungroup()
df.power$hour <- as.numeric(df.power$hour)
p <- ggplot(df.power, aes(x = hour, y = power, colour=operator)) +
geom_line() +
xlab("Hour of day") +
ylab("Average power level") +
ggtitle("Average power level") +
theme(axis.text.x = element_text(angle = 90)) +
scale_colour_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
df.power <- df %>%
group_by(operator, hour) %>%
summarise(power = mean(power)) %>%
ungroup()
df.power$hour <- as.numeric(df.power$hour)
p <- ggplot(df.power, aes(x = hour, y = power, colour=operator)) +
geom_line() +
xlab("Hour of day") +
ylab("Average power level") +
ggtitle("Average power level") +
scale_colour_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
df.start.perScooter <- df.trip[!is.na(df.trip$isStart),]
df.start.perScooter$day <- weekdays(df.start.perScooter$time, abbreviate = T)
df.start.perScooter <- df.start.perScooter %>%
group_by(operator, day) %>%
summarise(averageTripsPerScooter = sum(isStart) / length(unique(id)) / length(unique(cbind(month, day)))) %>%
ungroup()
p <- ggplot(df.start.perScooter, aes(x = day, y = averageTripsPerScooter, fill=operator), colour='black',size=0.02) +
geom_bar(stat="identity", colour='black',size=0.02,position='dodge') +
xlab("Day of week") +
ylab("Average trips per scooter") +
ggtitle("Estimated average trips per scooter (adjusted for days logged)") +
theme(axis.text.x = element_text(angle = 90)) +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
df.start.perScooter <- df.trip[!is.na(df.trip$isStart),]
df.start.perScooter <- df.start.perScooter %>%
group_by(operator, hour) %>%
summarise(averageTripsPerScooter = sum(isStart) / length(unique(id)) / length(unique(cbind(month, day)))) %>%
ungroup()
p <- ggplot(df.start.perScooter, aes(x = hour, y = averageTripsPerScooter, fill=operator), colour='black',size=0.02) +
geom_bar(stat="identity", colour='black',size=0.02) +
xlab("Hour of day") +
ylab("Average trips per scooter") +
ggtitle("Estimated average trips per scooter \n (adjusted for days logged)") +
theme(axis.text.x = element_text(angle = 90)) +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
df.start.perScooter <- df.trip[!is.na(df.trip$isStart),]
df.start.perScooter$day <- weekdays(df.start.perScooter$time, abbreviate = T)
df.start.perScooter <- df.start.perScooter %>%
group_by(operator, day) %>%
summarise(averageTripsPerScooter = sum(isStart) / length(unique(id)) / length(unique(cbind(month, day)))) %>%
ungroup()
p <- ggplot(df.start.perScooter, aes(x = day, y = averageTripsPerScooter, fill=operator), colour='black',size=0.02) +
geom_bar(stat="identity", colour='black',size=0.02,position='dodge') +
xlab("Day of week") +
ylab("Average trips per scooter") +
ggtitle("Estimated average trips per scooter \n (adjusted for days logged)") +
scale_fill_manual(values=c("#F56600","#6DDDb2","#F46C62","#009F1F"))
ggplotly(p)
View(df.unique)
View(p)
local({
# The directory where Pandoc will be extracted. Feel free
# to adjust this path as appropriate.
dir <- "~/rstudio-pandoc"
# The version of Pandoc to be installed.
version <- "2.7.1"
# Create and move to the requested directory.
dir.create(dir, showWarnings = FALSE, recursive = TRUE)
owd <- setwd(dir)
on.exit(setwd(owd), add = TRUE)
# Construct path to pandoc.
root <- "https://s3.amazonaws.com/rstudio-buildtools"
suffix <- sprintf("pandoc-%s-windows-x86_64.zip", version)
url <- file.path(root, "pandoc-rstudio", version, suffix)
# Download and extract pandoc.
file <- basename(url)
utils::download.file(url, destfile = file)
utils::unzip(file)
unlink(file)
# Write .Renviron to update the version of Pandoc used.
entry <- paste("RSTUDIO_PANDOC", shQuote(path.expand(dir)), sep = " = ")
contents <- if (file.exists("~/.Renviron")) readLines("~/.Renviron")
filtered <- grep("^RSTUDIO_PANDOC", contents, value = TRUE, invert = TRUE)
amended <- union(filtered, entry)
writeLines(amended, "~/.Renviron")
# Report change to the user.
writeLines("Updated .Renviron:\n")
writeLines(amended)
writeLines("\nPlease restart RStudio for these changes to take effect.")
})
